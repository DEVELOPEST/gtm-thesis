% TODO: Exsisting solutions comparison here?

We decided to have time tracking data stored in Git Notes for every repo so that it can be tightly tied to code.
This gives us opportunity to have more complete overview when and on what issue / branch the time was spent.
It also gives access to a features such as git diff that can be used for measuring writing speed.
Furthermore, it lifts a job from our shoulders by handling complex cases such as rebase and merge for us.

The downside is that git notes take up some space on client machine and Git server.
They can also be externally edited, and they might cause issues with git usage if developer does not follow best practices.
Nonetheless, we decided to go this way as the space used by git notes is fractional compared to file sizes, and our app is a tool for the developer,
so we don't see any urgent need to protect it from him.

Later it was brought out in gitlab time tracking issue discussion, that storing time data in git notes is a very clean approach.
However, they have not yet decided to implement it themselves as it requires major changes in their current business logic.
\cite{gitlab-time-issue}

We also found open source Command Line Interface (CLI) app made for local time-tracking with Git, so we decided to base our app on the already existing code and add more functionality.
There is always an option to switch to external database for storing this kind of data but there is no reason to so at the moment.

Partly enforced by the usage of git, the general design is shown on Figure
\ref{fig:project-archidecture}.

\begin{figure}[h]
    \includegraphics[width=\textwidth]{figures/project_archidecture}
    \caption{Application general design}
    \label{fig:project-archidecture}
\end{figure}

The general time-tracking application can be divided into three different kind of smaller applications:
\begin{enumerate}
    \item \textbf{Applications that are responsible for data collecting.} These applications are CLI app and IDE plugins and are installed on developers machine.
    \item \textbf{Applications that are responsible for syncing data.} This role is filled by a Sync client, and these applications are installed onto companies servers where they can access git internal network.
    \item \textbf{Applications that are responsible for analyzing and displaying data.} These are Frontend and Backend app that can be installed on any public server.
\end{enumerate}

The reasoning behind this architecture is scalability and security.
For every Backend there can be multiple Sync clients all installed on different machines and with different Git access rights.
For every Sync client there can be multiple Client apps all logging time independent of one another.
And in the end, there can be multiple IDE plugins interacting with CLI app.

For security, it is very important to ensure, that no sensitive information is leaked.
To deal with this issue many companies have their Git available only in an internal network.
Not to rise any more security concerns we decided to follow the same principle and not export any git code outside internal network.
That is the reason, why Sync client is needed as it has access to internal network, but only uploads time-tracking related information to our Backend.
Therefore, actual code never leaves an internal network.

All the applications that are installed on either client machine or client server are open source so that the client can easily verify,
they only do what they are meant to do.

To properly manage numerous apps in different programming languages we decided to have each app source code in separate git repository.
This reduces the amount of merge conflicts and also makes building CI/CD easier.


\section{Client CLI app}\label{sec:cli-app}
%TODO(Tavo): We should somewhere state what are gtm-core, gtm-api, gtm-*
This is the main app on client machine.
The app is responsible for storing events sent by an editor to files and then later also combining the stored information into Git Note.
You can also see all main stats, such as time spent on a commit via CLI app.

The app is based on open source time tracking app \href{https://github.com/git-time-metric/gtm}{Git-Time-Metric} written in Go and licenced under MIT licence.
We decided to base our app on Git-Time-Metric solution because their app was working the way we wanted to, it had plenty of users meaning plenty of testing done,
and the Git-Time-Metric app had good code style.

Gtm-core folder structure is displayed in Table
\ref{tab:gtm-core-folder-structure}.

\begin{table}[h]
    \centering
    \begin{tabular}{ | p{3cm} | p{10cm} |}
        \hline
        Folder & Purpose\\
        \hline
        .github & Github related files (Workflows for CI/CD, issues and pull requests templates)\\
        \hline
        deploy & Deploying related files.
        Currently, only Windows installer files and Licence packed with installer.\\
        \hline
        command & Every command has files <command>.go and <command>\_test.go which respectively are controller for command, and it's tests.
        The controller is responsible for parsing arguments, calling appropriate services and printing out results.\\
        \hline
        docs & Documentation files.\\
        \hline
        epoch & Unix epoch helper functions and their tests.\\
        \hline
        event & Events files serialization and deserialization related services and tests.\\
        \hline
        metric & Metric file serialization, deserialization services and tests.
        Metric files are used for storing time data of files added to git, but not committed.\\
        \hline
        note & Git notes serialization, deserialization and tests.\\
        \hline
        project & Gtm initialization and uninitialization related services with tests.
        These services are responsible for calling appropriate functions from scm package to git hooks and modifying git config.\\
        \hline
        report & Report generation services used by report command.\\
        \hline
        scm & Git related services.
        These services are used to wrap libgit2-go services into more usable form.\\
        \hline
        test & Python files for running stress tests for gtm-core.\\
        \hline
        util & Various string, datetime and math helper functions.\\
        \hline
        vendor & Directory containing dependencies listed in git submodules.\\
        \hline
        <root> & Program entry point, git related files, README and gofmt style lint configuration .\\
        \hline
    \end{tabular}
    \caption{Gtm-core folder structure.}
    \label{tab:gtm-core-folder-structure}
\end{table}

Although the app was already working we still needed to do many bug fixes and add some features it didn't have.
The biggest change in design was that we removed copied in dependencies to git submodules.
Although this seems like a small step it turned out to be very complex to build go linked with C library dynamically.
As we didn't manage to get on dependency to properly work in Windows environments we decided to leave it separately fetched and built in ci/cd workflow file.
Nonetheless, all "snapshot" dependencies were removed.
We also added stress tests to verify effect of using gtm-core with large amounts of commits.

\section{IDE plugins}\label{sec:ide-plugins}
IDE plugins installed on developer IDE, and they execute CLI app commands on specific editor events.
Plugins are needed to listen for editor events such as typing without having to give CLI app extensive permissions to run in background.
They also provide a simple way to display some information in IDE.
For example time since last commit is show to user inside IDE.

Currently, we only have one plugin that is compatible with all Jetbrains IDE's.
The gtm-jetbrains plugin is written in Kotlin and uploaded to Jetbrains plugin repository so that you can easily install it in your Jetbrains IDE.
Kotlin was chosen as the plugin was limited to JVM based language and only Java and Kotlin were widely supported.
We have experience in both Java and Kotlin, but we both preferred Kotlin to Java due to its null safety and functional patterns.

Gtm-jetbrains folder structure is described in Table
\ref{tab:gtm-jetbrains-folder-structure}.
Namespace \textit{ee.developest.gtm} is shortened to \textit{<ns>} for readability.

\begin{table}[h]
    \centering
    \begin{tabular}{ | p{3cm} | p{10cm} |}
        \hline
        Folder & Purpose\\
        \hline
        .gradle & Gradle related files\\
        \hline
        src/<ns>/listener & Editor event listeners.\\
        \hline
        src/<ns>/popup & Popups related controllers.
        Used for getting user input\\
        \hline
        src/<ns>/service & Service files such as ConfigService.kt\\
        \hline
        src/<ns>/widget & Widget factories used to display time since last commit and some feedback about initialization.\\
        \hline
        src/<ns> & Gtm-core wrapper used to forward commands from listeners to gtm-core and gtm-core to popup / widget.\\
        \hline
        <root> & Gradle configuration, README and LICENCE.\\
        \hline
    \end{tabular}
    \caption{Gtm-jetbrains folder structure.}
    \label{tab:gtm-jetbrains-folder-structure}
\end{table}

\section{Sync client}\label{sec:sync-client}
Sync client is run on a network, where it can access git repositories.
On git push, hook sends request to gtm-sync via HTTP request.
Then gtm-sync fetches git repository with its time data, extracts required data and syncs it up to Backend.

The gtm-sync application was written in Rust as it had more up to date library for libgit2 than both Java and Go, required for interacting with git.
Although we did not have prior experience with Rust we preferred it to C/C++ as it is memory safe and it has higher level libraries that can be
used for building a web server and API client.
Python and NodeJS were ruled out because they produce very big memory footprint compared to Rust, and they also run a lot slower.
Neither of them also gives a type safety that was a must for us.

For the code design, we followed domain based architecture.
Folder structure for gtm-sync is displayed in Table
\ref{tab:gtm-sync-folder-structure}.

\begin{table}[h]
    \centering
    \begin{tabular}{ | p{3cm} | p{10cm} |}
        \hline
        Folder & Purpose\\
        \hline
        .github & Github workflows.\\
        \hline
        src/config & Config serialization, deserialization and config helper functions.\\
        \hline
        src/gtm & Gtm notes parsing and git related services.\\
        \hline
        src/repo & Tracked repository managing services.\\
        \hline
        src/server & Rocket controllers used for IO.\\
        \hline
        src/sync & Syncing data with gtm-api related services.\\
        \hline
        <root> & Git related files, Cargo package manager files, README and LICENCE.\\
        \hline
    \end{tabular}
    \caption{Gtm-sync folder structure.}
    \label{tab:gtm-sync-folder-structure}
\end{table}

\section{Backend}\label{sec:backend}
Backend is a collection of code which runs on the server.
It receives requests from clients and sends appropriate data back to the clients based on the business logic.
Backend also has a database which stores all the necessary data for the application.
As a database system PostgresSQL was chosen as it is capable of reading and writing large amounts of data efficiently, and we already have considerable amount of experience with it.

In our case backend receives data from sync client via REST API requests and stores the data in the database.
End users can interact with backend though frontend via REST API requests.
%TODO: Kas peaks märkima, et paar endpointi (sync omad) on ka token authiga n-ö programmidele kättesaadavad?

Backend application has been built with Rust programming language using Rocket framework.
Rust is a relatively new low-level statically-typed programming language that's focused on performance and safety.
It gives all most the same speed as C++, but guarantees both memory and thread safety.
Since we needed a fast backend with minimal overhead for processing large datasets Rust was the best choice.
Java, C/C++ and GO were also considered, but the lightweightness of Rust overweight Java whilst memory safety overweight C/C++
and since Rust was chosen for sync client we decided to choose it for backend as well.

\subsection{Backend design}\label{subsec:backend-design}
Backend code base has been built following Domain Driven Design (DDD).
DDD is a concept that centers the development and code structure around the business domain.
It helps to keep the code more organized, maintainable and extendable \cite{domain-driven-design}.
% TODO: More explanation for DDD, some reference

A layered architecture can be found on Figure\ref{fig:backend-layered-diagram}
\begin{figure}[H]
    \includegraphics[width=\textwidth]{figures/backend_layered_diagram}
    \caption{Backend architecture}
    \label{fig:backend-layered-diagram}
\end{figure}

Folder structure is displayed in Table
\ref{tab:gtm-api-folder-structure}.
\begin{table}[h]
    \centering
    \begin{tabular}{ | p{3cm} | p{10cm} |}
        \hline
        Folder & Purpose\\
        \hline
        doc &  .\\ %TODO TAVO
        \hline
        migrations & Migrations for diesel. \\
        \hline
        src/common & Widely used files.\\
        \hline
        src/db & General database connection.\\
        \hline
        src/security & Authentication and authorization.\\
        \hline
        src/vcs & Version control.\\
        \hline
        <root> & Configurations, README and LICENCE.\\
        \hline
    \end{tabular}
    \caption{Gtm-api folder structure.}
    \label{tab:gtm-api-folder-structure}
\end{table}

\subsection{Database design}\label{subsec:database-design}
One requirement when choosing database was that we needed it to have bindings for our Object-relational mapper (ORM),
so we could easily use it in our application.
This requirement narrowed search down to SQLite, MySQL and PostgreSQL.
SQLite was ruled out as it is not strongly typed, and it does not have the same amount of features PostgreSQL and MySQL have.
For choosing between MySQL and PostgreSQL it came down to personal preference as both of them are strongly typed and
support all the required features, including recursive queries.
Both of them are also open source.

We decided to go with the PostgreSQL as we had prior experience with it.

As we are running the application in "beta" we decided to run database in docker container on our development machine to
reduce the cost of upkeep.
For data persistence we have mounted database files volume to host machine.

\subsubsection{Database versioning}\label{subsubsec:database-versioning}
As we have users data in our database it is important to also persist it through database schema updates.
For this we use migrations and let diesel handle the updates.
Every time database change is required, we add new migration with both up and down scripts that can be used by diesel
to run the migration or revert it.
Diesel is configured to automatically run updates added to release.
As reverting database changes can result in a loss of data, it has to be done manually via diesel CLI app.

\subsubsection{ERD Schema}\label{subsubsec:erd-schema}
The database holds data about tracked time, registered users and how the users can access time data.
The structure if the database schema is described in Figure~\ref{subsubsec:erd-schema}

Time data follows the structure of git commits tree and file tree.
The \textit{repositories} table contains general information about git repository such as name and the sync client
responsible for tracking it.
Then the \textit{commits} table has the information about commits such as author, timestamp and commit message.
Each \textit{commits} table entry has also reference to repository it is committed to.
Every commit has zero or more files that were edited in it.
These files are contained in \textit{files} table and they contain information about files added and deleted.
To have more accurate data about when the time was spent separate table is needed as there is no guarantee that
the time spent editing files is spent just before commit timestamp.
For this we have a table called \textit{timeline} which olds timestamps and durations of every consecutive edits as
well as reference to file in which the time was spent.

The user and roles table are responsible for persisting user login credentials, roles and connected OAuth accounts.
As we allow user to optionally register only via OAuth the password field is nullable.
Users that have no password can only log in via OAuth, but they can also add password at any time.

Every user can have multiple rows with role \textit{USER} being added to every user by default.
There are three roles in total: \textit{USER}, \textit{LECTURER} and \textit{ADMIN}.
Currently there are no rules in database for any of the roles which means all checks are done in software.
More detailed description about roles can be found in~\nameref{subsec:roles} subsection.

Every user also has zero or more OAuth logins stored in \textit{logins} table.
There is a limit that every user can have at maximum one OAuth login per login type.
If one already exists, it is updated instead of adding new.

User emails retrieved from OAuth providers are stored in \textit{emails} table to avoid unnecessary web requests.

\begin{figure}[H]
    \includegraphics[width=\textwidth]{figures/erd_schema}
    \caption{ERD schema}
    \label{fig:erd-schema}
\end{figure}

\section{Frontend}\label{sec:frontend}
Frontend is a software program or website which the user interacts with.
In our case frontend is a website where user can see time tracking data according to the privileges.
Although technically also CLI app can be considered frontend when we refer to frontend we only mean website.

Frontend has been build using ReactJS library.
According to the State of Frontend 2020 report ReactJS is the most used JavaScript framework and also the framework which developers want to learn or keep using the most.
It is faster than Angular, and it's somewhat functional style was more pealing for us than the style of Vue.
It was chosen as Marten, who's mostly responsible for frontend development has some experience with it.

\begin{figure}[h]
    \includegraphics[width=\textwidth]{figures/frontend_framework_popularity.png}
    \caption{Frontend framework popularity \cite{state-of-frontend-report}}
    \label{fig:frontend-framework-popularity}
\end{figure}

\subsection{Code design}\label{subsec:code-design}
Frontend code is written following the main principles promoted by ReactJS community and documentation.
For an example component's names use PascalCase, helper files use camelCase, folders use camelCase.
Code is divided into multiple files/components to prevent code repetition, inline CSS is avoided, liner is used to make code easier to use, service calls are in the separate file, etc.
To prove code quality and readability TypeScript was chosen as it is strongly typed language which JavaScript is not.
This decision was not made in the beginning of the project but as the code kept growing and readability suffered the decision was made.
One of the biggest reasons to switch from JavaScript to Typescript was that due to being strongly typed language,
TypeScript has better IDE support.
Folder structure is displayed in Table
\ref{tab:gtm-front-folder-structure}.

\begin{table}[h]
    \centering
    \begin{tabular}{ | p{3cm} | p{10cm} |}
        \hline
        Folder & Purpose\\
        \hline
        src/api & Service calls .\\
        \hline
        src/assets & Images and icons. \\
        \hline
        src/containers & Main container structure (Header, Footer, Content, etc.)\\
        \hline
        src/models & Easy peasy state management models.\\
        \hline
        src/reusable & components that can be reused.\\
        \hline
        src/routes & Routes.\\
        \hline
        src/scss & Style.\\
        \hline
        src/store & Store for state management.\\
        \hline
        src/utils & Helpers.\\
        \hline
        src/views & Views that are used once.\\
        \hline
        <root> & TypeScript configuration, package.json, README and LICENCE.\\
        \hline
    \end{tabular}
    \caption{Gtm-front folder structure.}
    \label{tab:gtm-front-folder-structure}
\end{table}

\subsection{User interface design}\label{subsec:user-interface-design}
User interface must be built keeping user in mind.
User experience is the most important part of web application.
If user does not have a good experience with the interface, it might be the end of the interaction between user and the application.
Since the team did not have any professional designers, CoreUI was a great choice to make design process much easier.
CoreUI is an Open Source Bootstrap Admin Template which is built on Bootstrap and written with readability in mind.
The design and easy usability were the decisive factors choosing CoreUI.

However, easy usability has its own downsides as the graphs were not as customizable.
For graphs Recharts was chosen.
Recharts is a composable charting library built on React components and D3.
It is much more customizable than CoreUI charts as it allows combining different bar charts, line charts, etc.
\cite{recharts-readme}

At this point the design problem arose again.
Designing graphs were done in the following manner:
\begin{itemize}
    \item Understand the functionality and create an initial component.
    \item Let it settle for some time and then discuss with team.
    \item Finalize component and release it for test users.
    \item Make final changes according to the users' feedback.
\end{itemize}
Design patterns such as graph sizes, colors, spacings, fonts etc. were chosen in such a way that it would look similar to CoreUI graphs.

\subsection{State management}\label{subsec:state-management}
State management does not have a certain winner.
Choosing a state management library comes down to personal preference.
We decided to use Easy Peasy which is built on the most popular state management library Redux.
Easy Peasy was chosen over Redux because Redux has steep learning curve but Easy Peasy is easy to use.
